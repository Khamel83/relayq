name: Atlas Video Processor

on:
  workflow_dispatch:
    inputs:
      task:
        description: 'Processing task type'
        required: true
        type: choice
        options:
        - download-transcribe
        - download-only
        - batch-process
        - metadata-extract
        - quality-analyze
        - thumbnail-generate
        - playlist-process
      source:
        description: 'Content source platform'
        required: true
        type: choice
        options:
        - youtube
        - vimeo
        - soundcloud
        - direct
      url:
        description: 'Video/audio URL or playlist URL'
        required: true
        type: string
      quality:
        description: 'Video quality (if applicable)'
        required: false
        type: choice
        options:
        - best
        - 1080p
        - 720p
        - 480p
        - audio-only
        default: 'best'
      transcription_model:
        description: 'Transcription model'
        required: false
        type: choice
        options:
        - large-v3
        - large-v2
        - large
        - medium
        - base
        default: 'large-v3'
      batch_size:
        description: 'Number of items to process (for batch tasks)'
        required: false
        type: string
        default: '5'

jobs:
  atlas-video-processing:
    runs-on: [self-hosted, macmini]
    timeout-minutes: 120
    outputs:
      ${{ steps.setup.outputs.job-id }}: ${{ steps.setup.outputs.job-id }}

    steps:
      - name: Setup Processing Environment
        id: setup
        run: |
          echo "=== ATLAS VIDEO PROCESSOR ==="
          echo "ğŸ¬ Task: ${{ inputs.task }}"
          echo "ğŸŒ Source: ${{ inputs.source }}"
          echo "ğŸ”— URL: ${{ inputs.url }}"
          echo "ğŸ¥ Quality: ${{ inputs.quality }}"
          echo "ğŸ¤– Model: ${{ inputs.transcription_model }}"
          echo ""

          # Create processing directory
          JOB_ID="atlas-$(date +%Y%m%d-%H%M%S)"
          echo "job-id=$JOB_ID" >> $GITHUB_OUTPUT
          WORKSPACE="/tmp/atlas-processing/$JOB_ID"
          mkdir -p "$WORKSPACE"/{raw,processed,metadata,transcripts,thumbnails}
          echo "âœ… Workspace created: $WORKSPACE"

          cd "$WORKSPACE"

          # Load environment
          if [[ -f "$HOME/.config/relayq/env" ]]; then
            source "$HOME/.config/relayq/env"
            echo "âœ… Environment loaded"
          fi

      - name: Download Content
        id: download
        run: |
          echo "ğŸ“¥ Downloading content from ${{ inputs.source }}..."
          cd /tmp/atlas-processing/${{ steps.setup.outputs.job-id }}

          case "${{ inputs.source }}" in
            "youtube")
              echo "ğŸ¬ Downloading from YouTube..."
              if [[ "${{ inputs.task }}" == "playlist-process" ]]; then
                echo "ğŸ“‹ Processing playlist..."
                yt-dlp --write-info-json --write-thumbnail \
                  --output "raw/%(playlist_index)s - %(title)s.%(ext)s" \
                  "${{ inputs.url }}"
              else
                yt-dlp --write-info-json --write-thumbnail \
                  --output "raw/%(title)s.%(ext)s" \
                  -f "best[height<=${{ inputs.quality }}]/bestaudio" \
                  "${{ inputs.url }}"
              fi
              ;;

            "vimeo")
              echo "ğŸ¬ Downloading from Vimeo..."
              yt-dlp --write-info-json --write-thumbnail \
                --output "raw/%(title)s.%(ext)s" \
                "${{ inputs.url }}"
              ;;

            "soundcloud")
              echo "ğŸµ Downloading from SoundCloud..."
              yt-dlp --write-info-json --write-thumbnail \
                --output "raw/%(title)s.%(ext)s" \
                -f "bestaudio" \
                "${{ inputs.url }}"
              ;;

            "direct")
              echo "ğŸ”— Downloading direct URL..."
              FILENAME=$(basename "${{ inputs.url }}")
              curl -L -o "raw/$FILENAME" "${{ inputs.url }}"
              # Create basic metadata
              echo "{\"url\": \"${{ inputs.url }}\", \"filename\": \"$FILENAME\"}" > "raw/$FILENAME.json"
              ;;
          esac

          # Count downloaded files
          FILE_COUNT=$(find raw -type f ! -name "*.json" ! -name "*.jpg" ! -name "*.png" | wc -l)
          echo "âœ… Downloaded $FILE_COUNT media files"
          echo "file-count=$FILE_COUNT" >> $GITHUB_OUTPUT

      - name: Extract Metadata
        if: steps.download.outputs.file-count > 0
        run: |
          echo "ğŸ“Š Extracting metadata..."
          cd /tmp/atlas-processing/${{ steps.setup.outputs.job-id }}

          for file in raw/*; do
            if [[ -f "$file" && ! "$file" =~ \.(json|jpg|png)$ ]]; then
              echo "ğŸ” Analyzing: $file"

              # Get media information
              if command -v ffprobe &> /dev/null; then
                ffprobe -v quiet -print_format json -show_format -show_streams "$file" > "metadata/$(basename "$file").probe.json"
              fi

              # Get file information
              stat -f "%N,%z,%m" "$file" > "metadata/$(basename "$file").stat"

              echo "âœ… Metadata extracted for $(basename "$file")"
            fi
          done

      - name: Transcribe Audio
        if: contains(inputs.task, 'transcribe') && steps.download.outputs.file-count > 0
        run: |
          echo "ğŸ™ï¸ Starting transcription with ${{ inputs.transcription_model }}..."
          cd /tmp/atlas-processing/${{ steps.setup.outputs.job-id }}

          python3 -c "
import whisper
import json
import os
import subprocess

def extract_audio(video_file):
    '''Extract audio from video file'''
    audio_file = video_file.rsplit('.', 1)[0] + '.mp3'
    if not os.path.exists(audio_file):
        print(f'ğŸµ Extracting audio from {video_file}...')
        subprocess.run([
            'ffmpeg', '-i', video_file, '-q:a', '0', '-map', 'a', audio_file, '-y'
        ], check=True, capture_output=True)
    return audio_file

def transcribe_file(audio_file, model_name):
    '''Transcribe audio file'''
    print(f'ğŸ¤– Loading {model_name} model...')
    model = whisper.load_model(model_name, device='mps')

    print(f'âš¡ Transcribing {audio_file}...')
    result = model.transcribe(audio_file, verbose=False, word_timestamps=True)

    return result

# Process all downloaded files
processed_count = 0
for file in os.listdir('raw'):
    if file.endswith(('.mp4', '.mkv', '.mov', '.avi', '.webm', '.mp3', '.m4a', '.wav')):
        print(f'\\nğŸ¬ Processing: {file}')

        try:
            video_file = os.path.join('raw', file)

            # Extract audio if needed
            if file.endswith(('.mp4', '.mkv', '.mov', '.avi', '.webm')):
                audio_file = extract_audio(video_file)
            else:
                audio_file = video_file

            # Transcribe
            result = transcribe_file(audio_file, '${{ inputs.transcription_model }}')

            # Save results
            base_name = os.path.splitext(file)[0]

            # Plain text transcript
            with open(f'transcripts/{base_name}.txt', 'w') as f:
                f.write(result['text'])

            # JSON with full data
            with open(f'transcripts/{base_name}.json', 'w') as f:
                json.dump(result, f, indent=2)

            # Summary info
            summary = {
                'file': file,
                'duration': result.get('segments', [])[-1].get('end', 0) if result.get('segments') else 0,
                'language': result.get('language', 'unknown'),
                'model': '${{ inputs.transcription_model }}',
                'word_count': len(result['text'].split()),
                'character_count': len(result['text'])
            }

            with open(f'metadata/{base_name}_transcription.json', 'w') as f:
                json.dump(summary, f, indent=2)

            print(f'âœ… Completed: {summary[\"character_count\"]} chars, {summary[\"duration\"]:.1f}s')
            processed_count += 1

        except Exception as e:
            print(f'âŒ Failed to process {file}: {e}')
            continue

print(f'\\nğŸ‰ Transcription completed: {processed_count} files processed')
"

      - name: Generate Thumbnails
        if: steps.download.outputs.file-count > 0
        run: |
          echo "ğŸ–¼ï¸ Generating thumbnails..."
          cd /tmp/atlas-processing/${{ steps.setup.outputs.job-id }}

          for file in raw/*; do
            if [[ -f "$file" && "$file" =~ \.(mp4|mkv|mov|avi|webm)$ ]]; then
              echo "ğŸ“¸ Creating thumbnail for $(basename "$file")..."

              # Generate multiple thumbnails
              ffmpeg -i "$file" \
                -ss 00:00:01 -vframes 1 "thumbnails/$(basename "$file" .mp4)_01.jpg" \
                -ss 00:00:10 -vframes 1 "thumbnails/$(basename "$file" .mp4)_10.jpg" \
                -ss 00:00:30 -vframes 1 "thumbnails/$(basename "$file" .mp4)_30.jpg" \
                -y 2>/dev/null || true

              # Generate preview GIF (first 3 seconds)
              ffmpeg -i "$file" \
                -t 3 -vf "fps=10,scale=320:-1:flags=lanczos" \
                "thumbnails/$(basename "$file" .mp4).gif" \
                -y 2>/dev/null || true
            fi
          done

      - name: Quality Analysis
        if: contains(inputs.task, 'analyze') && steps.download.outputs.file-count > 0
        run: |
          echo "ğŸ” Performing quality analysis..."
          cd /tmp/atlas-processing/${{ steps.setup.outputs.job-id }}

          python3 -c "
import json
import os
import subprocess
import re

def analyze_video_quality(file_path):
    '''Analyze video quality metrics'''
    try:
        # Get video information
        result = subprocess.run([
            'ffprobe', '-v', 'quiet', '-print_format', 'json',
            '-show_format', '-show_streams', file_path
        ], capture_output=True, text=True)

        info = json.loads(result.stdout)

        # Extract relevant streams
        video_stream = next((s for s in info['streams'] if s['codec_type'] == 'video'), None)
        audio_stream = next((s for s in info['streams'] if s['codec_type'] == 'audio'), None)

        analysis = {
            'file': os.path.basename(file_path),
            'size_bytes': os.path.getsize(file_path),
            'size_mb': round(os.path.getsize(file_path) / (1024*1024), 2)
        }

        if video_stream:
            analysis.update({
                'video_codec': video_stream.get('codec_name'),
                'resolution': f\"{video_stream.get('width')}x{video_stream.get('height')}\",
                'fps': eval(video_stream.get('r_frame_rate', '0/1')),
                'bitrate': int(video_stream.get('bit_rate', 0)) or int(info['format'].get('bit_rate', 0))
            })

        if audio_stream:
            analysis.update({
                'audio_codec': audio_stream.get('codec_name'),
                'audio_sample_rate': audio_stream.get('sample_rate'),
                'audio_channels': audio_stream.get('channels'),
                'audio_bitrate': int(audio_stream.get('bit_rate', 0))
            })

        return analysis

    except Exception as e:
        return {'file': os.path.basename(file_path), 'error': str(e)}

# Analyze all files
analysis_results = []
for file in os.listdir('raw'):
    if os.path.isfile(os.path.join('raw', file)):
        analysis = analyze_video_quality(os.path.join('raw', file))
        analysis_results.append(analysis)
        print(f'ğŸ“Š Analyzed: {analysis.get(\"file\", file)}')

# Save analysis results
with open('metadata/quality_analysis.json', 'w') as f:
    json.dump(analysis_results, f, indent=2)

print(f'\\nâœ… Quality analysis completed: {len(analysis_results)} files')
"

      - name: Create Processing Report
        run: |
          echo "ğŸ“‹ Creating processing report..."
          cd /tmp/atlas-processing/${{ steps.setup.outputs.job-id }}

          python3 -c "
import json
import os
from datetime import datetime

# Collect all information
report = {
    'job_id': '${{ steps.setup.outputs.job-id }}',
    'task': '${{ inputs.task }}',
    'source': '${{ inputs.source }}',
    'url': '${{ inputs.url }}',
    'quality': '${{ inputs.quality }}',
    'transcription_model': '${{ inputs.transcription_model }}',
    'timestamp': datetime.now().isoformat(),
    'files': []
}

# Process each file
for file in os.listdir('raw'):
    if os.path.isfile(os.path.join('raw', file)) and not file.endswith(('.json', '.jpg', '.png')):
        file_info = {
            'filename': file,
            'size_mb': round(os.path.getsize(f'raw/{file}') / (1024*1024), 2),
            'has_metadata': os.path.exists(f'metadata/{file}.probe.json') or os.path.exists(f'metadata/{file}.json'),
            'has_thumbnail': any(os.path.exists(f'thumbnails/{os.path.splitext(file)[0]}{ext}')
                               for ext in ['.jpg', '.gif']),
            'has_transcript': os.path.exists(f'transcripts/{os.path.splitext(file)[0]}.txt'),
            'transcript_chars': 0
        }

        # Get transcript character count
        if file_info['has_transcript']:
            with open(f'transcripts/{os.path.splitext(file)[0]}.txt', 'r') as f:
                file_info['transcript_chars'] = len(f.read())

        report['files'].append(file_info)

# Add summary
report['summary'] = {
    'total_files': len(report['files']),
    'total_size_mb': sum(f['size_mb'] for f in report['files']),
    'files_with_metadata': sum(1 for f in report['files'] if f['has_metadata']),
    'files_with_thumbnails': sum(1 for f in report['files'] if f['has_thumbnail']),
    'files_with_transcripts': sum(1 for f in report['files'] if f['has_transcript']),
    'total_transcript_chars': sum(f['transcript_chars'] for f in report['files'])
}

# Save report
with open('processing_report.json', 'w') as f:
    json.dump(report, f, indent=2)

# Print summary
print(f'\\nğŸ‰ PROCESSING COMPLETE')
print(f'ğŸ“ Job ID: ${ { steps.setup.outputs.job-id } }')
print(f'ğŸ“Š Files processed: {report[\"summary\"][\"total_files\"]}')
print(f'ğŸ’¾ Total size: {report[\"summary\"][\"total_size_mb\"]} MB')
print(f'ğŸ“ Transcripts: {report[\"summary\"][\"files_with_transcripts\"]}')
print(f'ğŸ“¸ Thumbnails: {report[\"summary\"][\"files_with_thumbnails\"]}')
print(f'ğŸ“‹ Metadata: {report[\"summary\"][\"files_with_metadata\"]}')
print(f'ğŸ“„ Total text: {report[\"summary\"][\"total_transcript_chars\"]} characters')
"

      - name: Upload Processing Results
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: atlas-processing-${{ steps.setup.outputs.job-id }}
          path: /tmp/atlas-processing/${{ steps.setup.outputs.job-id }}/
          retention-days: 30

      - name: Cleanup
        if: always()
        run: |
          echo "ğŸ§¹ Cleaning up..."
          rm -rf /tmp/atlas-processing/${{ steps.setup.outputs.job-id }}